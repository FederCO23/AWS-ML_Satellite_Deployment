{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee4fb12-cef9-451d-959b-5d305465e37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/satellite-ml-solarp-detection/Model_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import imageio.v2 as imageio  # Explicitly use version 2 API\n",
    "from torch.utils.data import get_worker_info\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.utils.data as data\n",
    "from torch.amp import autocast, GradScaler\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b1805a-8757-40eb-90ad-7f300b6a8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "transaction_ID = '200010' \n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ee273a-08fc-4b08-982e-8d02d09d4ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device (use GPU if available, otherwise fallback to CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a022e22-fe1e-4f41-93d3-1cbb3f928fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net model\n",
    "ENCODER = 'efficientnet-b7'\n",
    "#ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['solar_panel']\n",
    "ACTIVATION = 'sigmoid'\n",
    "\n",
    "model = smp.Unet(\n",
    "    in_channels = 4, #4 for all bands\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=None,  # No pretraining, since we are loading trained weights\n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14221676-cf40-41a7-ac47-332a6e909aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      4, 64, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          64, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1-3): 3 x MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5-10): 6 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12-17): 6 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19-27): 9 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (29-37): 9 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (38): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (39-50): 12 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (51): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (52-54): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          3840, 160, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          160, 3840, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(864, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(336, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(176, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained weights\n",
    "#Regular input images (256x256)\n",
    "#weights_path = os.path.join(os.path.expanduser(\"~\"), \"satellite-ml-solarp-detection\",\"models\", \"weights\", \"u-net_efficientnet-b7_v1\", \"unet-seed23_weights.pth\")\n",
    "#BiCubic Inter images x2 (512x512)\n",
    "weights_path = os.path.join(os.path.expanduser(\"~\"), \"satellite-ml-solarp-detection\",\"models\", \"weights\", \"u-net_efficientnet-b7_vBiC_intx2\", \"unet-seed23_wDA&Int_weights.pth\")\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    print(\"Model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: Weights file not found!\")\n",
    "    \n",
    "# Set model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c661a3-8471-4451-8151-9ca459a981b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numeric value from filenames\n",
    "def numeric_sort_key(filepath):\n",
    "    match = re.search(r'\\d+', filepath)\n",
    "    return int(match.group()) if match else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06150e38-cea0-4a0c-9c14-15f11bc24c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the input images and sort them numerically\n",
    "\n",
    "#OLD, getting images from acquisition (without image Enhancement / SR)\n",
    "# folder_data_input = sorted(\n",
    "#     glob.glob(os.path.join(os.path.expanduser(\"~\"), \"satellite-ml-solarp-detection\",\"acquisition\", transaction_ID, \"*tif\")),\n",
    "#     key=numeric_sort_key\n",
    "# )\n",
    "folder_data_input = sorted(\n",
    "    glob.glob(os.path.join(os.path.expanduser(\"~\"), \"satellite-ml-solarp-detection\",\"image_enhancement\", transaction_ID, \"*tif\")),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_image_paths = folder_data_input[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907d3ab0-a858-4ad8-bba9-fa83aaa851e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_000_000.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_001_000.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_002_000.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_003_000.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_000_001.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_001_001.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_002_001.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_003_001.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_000_002.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_001_002.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_002_002.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_003_002.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_000_003.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_001_003.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_002_003.tif', '/home/sagemaker-user/satellite-ml-solarp-detection/image_enhancement/200010/200010_003_003.tif']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Number of files in the acquisition ID \"200010\": 16\n"
     ]
    }
   ],
   "source": [
    "print(input_image_paths)\n",
    "print(120*\"-\")\n",
    "print(f'Number of files in the acquisition ID \"{transaction_ID}\": {len(input_image_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a52503-6e1e-496a-8ecf-32aa6705aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(image_paths, num_samples=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot histograms for each band (R, G, B, NIR) for a given sample of images.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "    nir_values = []\n",
    "    \n",
    "    # Iterate over a subset of images\n",
    "    for img_path in image_paths[:num_samples]:  \n",
    "        image = imageio.imread(img_path)\n",
    "        \n",
    "        # Separate the bands\n",
    "        red_values.extend(image[:, :, 0].flatten())\n",
    "        green_values.extend(image[:, :, 1].flatten())\n",
    "        blue_values.extend(image[:, :, 2].flatten())\n",
    "        nir_values.extend(image[:, :, 3].flatten())\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(red_values, bins=50, color='red', alpha=0.7)\n",
    "    plt.title(\"Red Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(green_values, bins=50, color='green', alpha=0.7)\n",
    "    plt.title(\"Green Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(blue_values, bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(\"Blue Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(nir_values, bins=50, color='purple', alpha=0.7)\n",
    "    plt.title(\"NIR Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4105e0f8-65b3-4738-8d92-bcf0ac7a0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with your training image paths\n",
    "#plot_histograms(input_image_paths, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4c4cab-b21c-41c5-ab3f-0f3570350ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, image_paths, transform=None, band=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.band = band # Specify which band to use (0: R, 1: G, 2: B, 3: NIR, None: all bands)\n",
    "        self.scaler = MinMaxScaler() \n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            image = imageio.imread(self.image_paths[index]).astype(np.float32)\n",
    "    \n",
    "            # Select a specific band if specified\n",
    "            if self.band is not None:\n",
    "                image = image[:, :, self.band] #Select only the specified band\n",
    "                image = image[:, :, np.newaxis]\n",
    "                \n",
    "            # # Normalize the image\n",
    "            # image_reshaped = image.reshape(-1, image.shape[-1])\n",
    "            # image_scaled = self.scaler.fit_transform(image_reshaped)\n",
    "            # image = image_scaled.reshape(image.shape)\n",
    "    \n",
    "            # Reshape for MinMaxScaler and apply normalization\n",
    "            image_reshaped = image.reshape(-1, 4)\n",
    "            image_scaled = self.scaler.fit_transform(image_reshaped)\n",
    "            image = image_scaled.reshape(image.shape)\n",
    "            \n",
    "            # Apply the transformation to both image and mask if self.transform is set\n",
    "            if self.transform:\n",
    "                image = self.transform(image)  # Pass both to transform if synchronized\n",
    "            return image, self.image_paths[index]    # Return image and corresponding filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {index}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, image):\n",
    "        return torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # Convert image to [C, H, W]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe1611b-d610-48a5-94a4-55b1a0123b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image shape: torch.Size([4, 512, 512]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CustomDataset objects\n",
    "use_all_bands = True\n",
    "model_band = None # 0:red, 1:green, 2:blue, 3:NIR, None:all 4 bands\n",
    "\n",
    "input_dataset = CustomDataset(input_image_paths, transform=ToTensor(), band=model_band)\n",
    "\n",
    "image = input_dataset[0]  # Load the first item\n",
    "print(f\"Transformed image shape: {image[0].shape}, dtype: {image[0].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d01bd3f-8eac-443f-b22e-e538a38e4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(dataset, num_samples=3):\n",
    "    for i in range(num_samples):\n",
    "        image = dataset[i]\n",
    "        \n",
    "        # Display input image and mask side-by-side\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image[0].permute(1, 2, 0))  # Convert CHW to HWC for display\n",
    "        plt.title(\"Input Image\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "744ebdfb-89c2-4a18-b0f3-134a3d4ea33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_images(input_dataset, num_samples=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e62b62a-e194-4741-9df8-f4675bcc5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace DataLoader setup for training, validation, and testing\n",
    "input_loader = torch.utils.data.DataLoader(input_dataset, batch_size=40, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b51379-c9f9-4157-a533-402e600bcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving predictions\n",
    "\n",
    "output_dir = os.path.join(os.path.expanduser(\"~\"), \"satellite-ml-solarp-detection\", \"prediction\", transaction_ID)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f80acc-c379-49c2-939f-4a6cb9f6d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_000_000.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_001_000.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_002_000.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_003_000.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_000_001.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_001_001.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_002_001.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_003_001.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_000_002.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_001_002.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_002_002.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_003_002.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_000_003.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_001_003.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_002_003.tif\n",
      "Saved with CRS: /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010/pred_200010_003_003.tif\n",
      "All predictions saved in /home/sagemaker-user/satellite-ml-solarp-detection/prediction/200010\n"
     ]
    }
   ],
   "source": [
    "# Prediction loop\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, image_paths) in enumerate(input_loader):\n",
    "        images = images.to(device)\n",
    "        predictions = model(images)\n",
    "        predictions = (predictions > threshold).int().cpu().numpy()\n",
    "        \n",
    "        # Save each prediction with CRS information\n",
    "        for i in range(len(images)):\n",
    "            filename = os.path.basename(image_paths[i])\n",
    "            save_path = os.path.join(output_dir, f\"pred_{filename}\")\n",
    "            pred_image = predictions[i].squeeze().astype(np.float32)\n",
    "            \n",
    "            # Read CRS and transform from source image\n",
    "            with rasterio.open(image_paths[i]) as src:\n",
    "                profile = src.profile.copy()\n",
    "                profile.update(\n",
    "                    dtype=rasterio.float32,\n",
    "                    count=1,\n",
    "                    compress='lzw'\n",
    "                )\n",
    "                \n",
    "                with rasterio.open(save_path, 'w', **profile) as dst:\n",
    "                    dst.write(pred_image, 1)\n",
    "                    print(f\"Saved with CRS: {save_path}\")\n",
    "\n",
    "print(f\"All predictions saved in {output_dir}\")\n",
    "\n",
    "# # Prediction loop\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (images, image_paths) in enumerate(input_loader):\n",
    "#         images = images.to(device)\n",
    "#         predictions = model(images)\n",
    "#         predictions = (predictions > threshold).int().cpu().numpy()\n",
    "        \n",
    "#         # Save each prediction\n",
    "#         for i in range(len(images)):\n",
    "#             filename = os.path.basename(image_paths[i])\n",
    "#             save_path = os.path.join(output_dir, f\"pred_{filename}\")\n",
    "#             pred_image = predictions[i].squeeze().astype(np.float32)\n",
    "#             imageio.imwrite(save_path, pred_image)\n",
    "#             print(f\"Saved: {save_path}\")\n",
    "\n",
    "# print(f\"All predictions saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6af87f-f37c-4bc4-9988-e432f57226f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909944f0-4e56-4059-9b13-f4bf7be39577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d8b34-4aa8-4c46-aea0-5e6e62857982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Model_env",
   "language": "python",
   "name": "model_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
